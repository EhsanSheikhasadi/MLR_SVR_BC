{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLR_SVR_BC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOw3VAU87za+AvsPQBETIaf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EhsanSheikhasadi/MLR_SVR_BC/blob/main/MLR_SVR_BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwG7FOvWFsZN"
      },
      "source": [
        "**Developing a transformed linear regression and support vector regression to deal with the demand uncertainty**\n",
        "\n",
        "Ehsan Sheikhasadia, Saiedeh Gholamia, Donya Rahmania, Hamid Esmaeili Najafabadib\n",
        "\n",
        "This is the code of the paper titled as \"Developing a transformed linear regression and support vector regression to deal with the demand uncertainty: Application to blood supply chain in disaster\", you can find the data from https://github.com/EhsanSheikhasadi/MLR_SVR_BC\n",
        "\n",
        "Contact: ehsan.sheikhasadi1994@gmail.com\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "mYVs_9kpBWYH",
        "outputId": "26769658-96e3-45b7-9421-816b717c224d"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Set the display format for the Floating Point numbers\n",
        "pd.options.display.float_format = \"{:,.2f}\".format\n",
        "\n",
        "# To store dataset in a Pandas Dataframe\n",
        "df = pd.read_excel(\"Iran_Natural_Disaster.xlsx\")\n",
        "\n",
        "#check if we have any missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "\n",
        "#our columns we need for model\n",
        "model_columns=df[['Earthquake  Magnitude','Focal Depth','direct distance from epicenter to nearest city',\n",
        "                  'Number of Homeless','Max PGA(%g)','Number of Injuries']]\n",
        "model_columns_names=['Earthquake  Magnitude','Focal Depth','direct distance from epicenter to nearest city',\n",
        "                  'Number of Homeless','Max PGA(%g)','Number of Injuries']\n",
        "\n",
        "#our features(independent variables)\n",
        "X=df[['Earthquake  Magnitude','Focal Depth','direct distance from epicenter to nearest city',\n",
        "                  'Number of Homeless','Max PGA(%g)']]\n",
        "X_name=['Earthquake  Magnitude','Focal Depth','direct distance from epicenter to nearest city',\n",
        "                  'Number of Homeless','Max PGA(%g)']\n",
        "\n",
        "\n",
        "#dependent variable\n",
        "Y=df['Number of Injuries']\n",
        "\n",
        "#creating histograms for each column to check the distribution of data in each column\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(20,20))\n",
        "for i, feature in enumerate(model_columns):\n",
        "    ax = fig.add_subplot(2, 3, i+1)\n",
        "    df[feature].hist(bins='auto', ax=ax, facecolor='#2ab0ff')\n",
        "    ax.set_title(feature, color='black')\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Box-Cox transportation\n",
        "from scipy import stats\n",
        "Mag_trans, lmbda = stats.boxcox(df['Number of Injuries'])\n",
        "print('Best lambda parameter = %s' % round(lmbda, 3))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "prob = stats.boxcox_normplot(df['Number of Injuries'], -20, 20, plot=ax)\n",
        "ax.axvline(lmbda, color='r');\n",
        "plt.show()\n",
        "\n",
        "# fit Gaussian distribution\n",
        "\n",
        "# Mag_trans.sort()\n",
        "mean, std = stats.norm.fit(Mag_trans, loc=0)\n",
        "pdf_norm = stats.norm.pdf(Mag_trans, mean, std)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "ax.hist(Mag_trans, bins='auto', density=True)\n",
        "ax.plot(Mag_trans, pdf_norm, label='Fitted normal distribution')\n",
        "ax.set_xlabel('Number of Injuries')\n",
        "ax.set_ylabel('Transformed Probability')\n",
        "ax.set_title('Box-Cox Transformed Distribution of Dependent Variable')\n",
        "ax.legend();\n",
        "plt.show()\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
        "\n",
        "prob = stats.probplot(df['Number of Injuries'], dist=stats.norm, plot=ax1)\n",
        "prob = stats.probplot(Mag_trans, dist=stats.norm, plot=ax2)\n",
        "\n",
        "#Visual Inspection with Q-Q Plots\n",
        "ax1.set_title('Original Data')\n",
        "ax1.set_ylabel('Number of Injuries')\n",
        "ax2.set_title('Transforamed Number of Injuries, Î» = %s' % -0.006);\n",
        "ax2.set_ylabel('');\n",
        "plt.show()\n",
        "\n",
        "#Normality Test with Hypothesis Testing\n",
        "k2, p = stats.normaltest(Mag_trans)\n",
        "print('\\nChi-squared statistic = %.3f, p = %.3f' % (k2, p))\n",
        "\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "    print('\\nThe transformed data is Gaussian (fails to reject the null hypothesis)')\n",
        "else:\n",
        "    print('\\nThe transformed data does not look Gaussian (reject the null hypothesis)')\n",
        "\n",
        "print(list(Mag_trans))\n",
        "print(np.array(df['Number of Injuries']))\n",
        "\n",
        "#Box Plot\n",
        "\n",
        "import seaborn as sb\n",
        "fig = plt.figure(figsize=(20,20))\n",
        "for i in range(6):\n",
        "     if i > 0:\n",
        "         ax = fig.add_subplot(2, 3, i+1)\n",
        "         sb.boxplot(data=model_columns.iloc[:,i])\n",
        "         ax.set_title(model_columns_names[i], color='black')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Correlations between the dependent variable and the independent variables\n",
        "   # Create an empty Data Frame to store all the Correlations\n",
        "corrdf = pd.DataFrame(columns = ['D V', 'Feature','Correlation']);\n",
        "\n",
        "# Loop through all the Features in scope\n",
        "df1 = df['Earthquake  Magnitude'];\n",
        "for j in model_columns.iloc[:,1:6].columns:\n",
        "     df2 = df[j]\n",
        "     c = df1.corr(df2)\n",
        "     corrdf = corrdf.append({'D V':'Earthquake  Magnitude','Feature':j, 'Correlation':c}, ignore_index = True);\n",
        "\n",
        "print(corrdf)\n",
        "\n",
        "\n",
        "# Build our Regression Models\n",
        "#Create the Training and Test Setsel\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_test = train_test_split(model_columns, train_size=0.7, random_state=44)\n",
        "y_train = df_train[['Number of Injuries']]\n",
        "x_train = df_train.drop(\"Number of Injuries\", axis=1)\n",
        "y_test = df_test[['Number of Injuries']]\n",
        "x_test = df_test.drop(\"Number of Injuries\", axis=1)\n",
        "train_x, test_x,train_y,test_y = train_test_split(X, Y , train_size=0.7\n",
        "                                                   , random_state=44)\n",
        "print(df_train.shape)\n",
        "\n",
        "\n",
        "# \"\"\"Build the Multiple Linear Regression Model\"\"\"\n",
        "#\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lr = LinearRegression(normalize = True)\n",
        "lr.fit(x_train, y_train)\n",
        "\n",
        "y_pred_train = lr.predict(x_train)\n",
        "print(y_pred_train)\n",
        "\n",
        "\n",
        "#Check the Metrics\n",
        "\n",
        "import sklearn.metrics as sm\n",
        "print(\"Mean absolute error =\", round(sm.mean_absolute_error(y_train,y_pred_train), 2))\n",
        "print(\"Mean squared error =\", round(sm.mean_squared_error(y_train,y_pred_train), 2))\n",
        "print(\"Median absolute error =\", round(sm.median_absolute_error(y_train,y_pred_train), 2))\n",
        "print(\"Explain variance score =\", round(sm.explained_variance_score(y_train,y_pred_train), 2))\n",
        "print(\"R2 score =\", round(sm.r2_score(y_train, y_pred_train), 2))\n",
        "\n",
        "# print(\"/\")\n",
        "\n",
        "y_pred_test = lr.predict(x_test)\n",
        "print(\"Mean absolute error =\", round(sm.mean_absolute_error(y_test,y_pred_test), 2))\n",
        "print(\"Mean squared error =\", round(sm.mean_squared_error(y_test, y_pred_test),2))\n",
        "print(\"Median absolute error =\", round(sm.median_absolute_error(y_test,y_pred_test), 2))\n",
        "print(\"Explain variance score =\", round(sm.explained_variance_score(y_test,y_pred_test), 2))\n",
        "print(\"R2 score =\", round(sm.r2_score(y_test, y_pred_test), 2))\n",
        "\n",
        "\n",
        "\"\"\"Build the Regression Model using Random Forest Algorithm\"\"\"\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "rf = make_pipeline(StandardScaler(), RandomForestRegressor())\n",
        "rf.fit(x_train, y_train)\n",
        "\n",
        "y_pred_train = rf.predict(x_train)\n",
        "print(y_pred_train)\n",
        "\n",
        "print(\"Mean absolute error =\", round(sm.mean_absolute_error(y_train,y_pred_train), 2))\n",
        "print(\"Mean squared error =\", round(sm.mean_squared_error(y_train,y_pred_train), 2))\n",
        "print(\"Median absolute error =\", round(sm.median_absolute_error(y_train,y_pred_train), 2))\n",
        "print(\"Explain variance score =\", round(sm.explained_variance_score(y_train,y_pred_train), 2))\n",
        "print(\"R2 score =\", round(sm.r2_score(y_train, y_pred_train), 2))\n",
        "\n",
        "# # print(\"/\")\n",
        "\n",
        "y_pred_test = rf.predict(x_test)\n",
        "print(\"Mean absolute error =\", round(sm.mean_absolute_error(y_test,y_pred_test), 2))\n",
        "print(\"Mean squared error =\", round(sm.mean_squared_error(y_test, y_pred_test),2))\n",
        "print(\"Median absolute error =\", round(sm.median_absolute_error(y_test,y_pred_test), 2))\n",
        "print(\"Explain variance score =\", round(sm.explained_variance_score(y_test,y_pred_test), 2))\n",
        "print(\"R2 score =\", round(sm.r2_score(y_test, y_pred_test), 2))\n",
        "\n",
        "\n",
        "\"\"\"Build Regression Model using SVM\"\"\"\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "svr = make_pipeline(StandardScaler(), SVR(C = 1500.0, epsilon = 0.9))\n",
        "svr.fit(x_train, y_train)\n",
        "\n",
        "y_pred_train = svr.predict(x_train)\n",
        "print(\"Mean absolute error =\", round(sm.mean_absolute_error(y_train,y_pred_train), 2))\n",
        "print(\"Mean squared error =\", round(sm.mean_squared_error(y_train,y_pred_train), 2))\n",
        "print(\"Median absolute error =\", round(sm.median_absolute_error(y_train,y_pred_train), 2))\n",
        "print(\"Explain variance score =\", round(sm.explained_variance_score(y_train,y_pred_train), 2))\n",
        "print(\"R2 score =\", round(sm.r2_score(y_train, y_pred_train), 2))\n",
        "\n",
        "# print(\"/\")\n",
        "\n",
        "y_pred_test = svr.predict(x_test)\n",
        "print(\"Mean absolute error =\", round(sm.mean_absolute_error(y_test,y_pred_test), 2))\n",
        "print(\"Mean squared error =\", round(sm.mean_squared_error(y_test, y_pred_test),2))\n",
        "print(\"Median absolute error =\", round(sm.median_absolute_error(y_test,y_pred_test), 2))\n",
        "print(\"Explain variance score =\", round(sm.explained_variance_score(y_test,y_pred_test), 2))\n",
        "print(\"R2 score =\", round(sm.r2_score(y_test, y_pred_test), 2))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a7bcc0ecadf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# To store dataset in a Pandas Dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"G:\\Paper CAIE\\Iran_Natural_Disaster_2.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#check if we have any missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'G:\\\\Paper CAIE\\\\Iran_Natural_Disaster_2.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5fljF1DBc2v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}